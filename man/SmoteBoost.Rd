% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/smoteboost-class.r
\name{SMOTEBoost}
\alias{SMOTEBoost}
\title{Creates SMOTEBoost models for regression tasks}
\usage{
SMOTEBoost(form, data, modeltype = "RQ", model_pars = NULL,
  perc_over = 0.8)
}
\arguments{
\item{form}{A formula describing the prediction problem}

\item{data}{A data frame containing the training data}

\item{modeltype}{Type of SMOTEBoost method. This package implements 5 different proposals:
\describe{
\item{\strong{R2}}{SMOTEBoost.R2 using boosting method AdaBoost.R2 proposed by Drucker (1997).}
\item{\strong{BEM}}{SMOTBoost.BM using boosting method BEMBoost proposed by Feely (2000).}
\item{\strong{RT}}{SMOTEBoost.RT using boosting method AdaBoost.RT proposed by Solomatine and Shrestha (2004).}
\item{\strong{RTPlus}}{SMOTEBoost+ using boosting method AdaBoost+ proposed by Kankanala et al. (2014).}
\item{\strong{RQ}}{SMOTEBoost.RQ using boosting method AdaBoost.RQ proposed by package authors (publication in progress). Nutshell: uses the median of errors as a dynamic threshold.}
}}

\item{model_pars}{A list with available parameters in creating decision trees and guiding the boosting process. Each boosting method allows for different parameters, which are detailed as follows:
\describe{
\item{\strong{For SMOTEBoost.R2}}{
\strong{niter}, the number of boosting iterations;
\strong{power} Exponent used to calculate the weight of each decision tree. Common values are 1 (linear), 2 (quadratic, default), 3 (cubic).
}
\item{\strong{For SMOTEBoost.BEM}}{
\strong{niter}, the number of boosting iterations;
\strong{BEM}, the Big Error Margin: a value that defines which errors (absolute distance) should be considered as being big.
}
\item{\strong{For SMOTEBoost.RT}}{
\strong{niter}, the number of boosting iterations;
\strong{thr}, absolute relative error threshold used to define prediction cases as hard to predict;
\strong{power}, exponent used to calculate the weight of each decision tree. Common values are 1 (linear), 2 (quadratic, default), 3 (cubic).
}
\item{\strong{For SMOTEBoost+}}{
\strong{niter}, the number of boosting iterations;
\strong{thr}, absolute relative error threshold used to define prediction cases as hard to predict;
\strong{power} Exponent used to calculate the weight of each decision tree. Common values are 1 (linear), 2 (quadratic, default), 3 (cubic);
\strong{sigma}, value used for regularization (default 0.5). If no regularization is expected, use NULL.
}
\item{\strong{For SMOTEBoost.RQ}}{
\strong{niter}, the number of boosting iterations;
\strong{power} Exponent used to calculate the weight of each decision tree. Common values are 1 (linear), 2 (quadratic, default), 3 (cubic).
}
}}

\item{perc_over}{Over-sampling percentage to apply to randomly selected cases with extreme values, e.g. 1 for 100\% oversampling. Default is 0.8 (80\% oversampling).}
}
\description{
Creates a SMOTEBoost class model containing information that describes a SMOTEBoost model for standard and imbalanced regression tasks. In a nutshell, this method combines the application of the resampling strategy SMOTE in each round of boosting, in order to bias each decision tree towards a better representation of uncommon cases, i.e. with extreme target values.
}
\examples{
library(ReBoost)
data(iris)
ind <- sample(0.75*nrow(iris))
tr <- iris[ind,]
ts <- iris[-ind,]
form<-Sepal.Length ~ .

#For SMOTEBoost.RQ
m1 <- SMOTEBoost(form, tr, modeltype = "RQ", model_pars = NULL); predict(m1, ts)
m1p <- SMOTEBoost(form, tr, modeltype = "RQ", model_pars = list(niter=100,power=2), perc_over=1); predict(m1p, ts)

#For SMOTEBoost.R2
m2 <- SMOTEBoost(form, tr, modeltype = "R2", model_pars = NULL); predict(m2, ts)
m2p <- SMOTEBoost(form, tr, modeltype = "R2", model_pars = list(niter=100,power=2), perc_over=1); predict(m2p, ts)

#For SMOTEBoost.RT
m3 <- SMOTEBoost(form, tr, modeltype = "RT", model_pars = NULL); predict(m3, ts)
m3p <- SMOTEBoost(form, tr, modeltype = "RT", model_pars = list(niter=100,thr=0.1,power=2), perc_over=1); predict(m3p, ts)

#For SMOTEBoost.RT+
m4 <- SMOTEBoost(form, tr, modeltype = "RTPlus", model_pars = NULL); predict(m4, ts)
m4p <- SMOTEBoost(form, tr, modeltype = "RTPlus", model_pars = list(niter=100,thr=0.1,power=2,sigma=0.5), perc_over=1); predict(m4p, ts)

#For BEMBoost
m5 <- SMOTEBoost(form, tr, modeltype = "BEM", model_pars = NULL); predict(m5, ts)
m5p <- SMOTEBoost(form, tr, modeltype = "BEM", model_pars = list(niter=100,BEM=0.5), perc_over=1); predict(m5p, ts)

}
\references{
N. Moniz, R. P. Ribeiro, V. Cerqueira, N. Chawla (2018). "SMOTEBoost for Regression: Improving the Prediction of Extreme Values", in Proceedings of the 5th IEEE International Conference on Data Science and Advanced Analytics, IEEE Xplore. 2018.


H. Drucker, “Improving regressors using boosting techniques”, in Proceedings of the Fourteenth International Conference on Machine Learning, ICML’97, Morgan Kaufmann Publishers Inc., pp. 107–115. 1997.


R. Feely, “Predicting stock market volatility using neural networks", Ph.D. Dissertation, Trinity College, Dublin, 2000.


D. P. Solomatine and D. L. Shrestha, “Adaboost.rt: a boosting algorithm for regression problems,” in 2004 IEEE International Joint Conference on Neural Networks, vol. 2, pp. 1163–1168 vol.2, 2004.

P. Kankanala, S. Das, and A. Pahwa, “Adaboost+: An ensemble learning approach for estimating weather-related outages in distribution systems", IEEE Transactions on Power Systems, vol. 29, no. 1, pp. 359–367, 2014.
}
\keyword{internal}
